{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Post\n",
    "In this project, we'll work with a dataset of submissions to popular technology site [Hacker News](https://news.ycombinator.com/). Hacker News is a site where user-submitted stories (known as \"posts\") receive votes and comments, similar to reddit.  We're specifically interested in analysing posts with titles that begin with either;\n",
    "\n",
    "- **Ask HN** :- where users submit the posts using the tag to ask the community a specific question. Or;\n",
    "\n",
    "- **Show HN** :- where users submit posts to show the community a project, or just something interesting.\n",
    "\n",
    "The whole dataset can be found [here](https://www.kaggle.com/datasets/hacker-news/hacker-news-posts), but we have reduced the length of the dataset to approximately 20,000 rows by removing all submissions that didn't receive any comments.\n",
    "\n",
    "The aim of of analysis is to dertmine:\n",
    "1. which posts, amont the two(AskHN and ShowHN) receive more comments on average.\n",
    "2. The appropriate time(hours) to create a post with high chances of receiving comments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the Dataset\n",
    "We'll start by importing, opening and reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "#import the data and explore the first five rows\n",
    "\n",
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']]\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "#Removing headers from a list of Lists\n",
    "\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "headers = hn[:1]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print('\\n')\n",
    "print(hn[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below highlights the descriptions of the table with the contents therein\n",
    "\n",
    "| Column | Description |\n",
    "|--------|-------------|\n",
    "|\"id\"    | Hacker News unique identifier|\n",
    "|\"title\" | Title of the Post|\n",
    "|\" url\"  | URL link to the post|\n",
    "|\"num_points\" | Number of points the post acquired|\n",
    "|\"num_comments\" | Number of comments on the post|\n",
    "|\"author\"| Username of the person who submitted the post|\n",
    "|\"created_at\" | Date and time of the post's submission|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Ask HN and Show HN Posts\n",
    "- Since we're only concerned with post titles beginning with Ask HN or Show HN, we'll create new lists of lists containing just the data for those titles.\n",
    "- We'll use the string method `startwith` to find the posts that begin either with **Ask HN** or **Show HN**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of ask_posts: 1744\n",
      "No. of show_posts: 1162\n",
      "No. of other_posts: 17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for post in hn:\n",
    "    title = post[1]\n",
    "    \n",
    "    if title.lower().startswith(\"ask hn\"):\n",
    "        ask_posts.append(post)\n",
    "        \n",
    "    elif title.lower().startswith(\"show hn\"):\n",
    "        show_posts.append(post)\n",
    "        \n",
    "    else:\n",
    "        other_posts.append(post)\n",
    "        \n",
    "print('No. of ask_posts:' , str(len(ask_posts)))\n",
    "print('No. of show_posts:' , str(len(show_posts)))\n",
    "print('No. of other_posts:' , str(len(other_posts)))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average No. of Comments for Ask HN and Show HN Posts\n",
    "\n",
    "The specific objective of this analysis to focus on the post that receives more comments on average hence  between the two posts, we'll calculate the average and proceed with the post that has a higher average value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.04\n"
     ]
    }
   ],
   "source": [
    "##Average no. of comments for Ask HN\n",
    "\n",
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    num_comment = int(post[4])\n",
    "    total_ask_comments += num_comment\n",
    "\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "\n",
    "#convert the average value to precisionof two\n",
    "#decimal placesusing the string.format() method\n",
    "print('{:.2f}'.format(avg_ask_comments)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.32\n"
     ]
    }
   ],
   "source": [
    "##Average no. of comments for Show HN\n",
    "\n",
    "total_show_comments = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    num_comment = int(post[4])\n",
    "    total_show_comments += num_comment\n",
    "\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "\n",
    "print('{:.2f}'.format(avg_show_comments))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the illustrations above, the figures demonstrates that **Ask HN** averages ```4 comments``` more than the __Show HN__ at any particular occurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Number of Ask Posts and Comments by Hour Created\n",
    "\n",
    "- Our objective is to determine if ask posts created at a certain _time_ are more likeliy to attract comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'09': 251,\n",
       " '13': 1253,\n",
       " '10': 793,\n",
       " '14': 1416,\n",
       " '16': 1814,\n",
       " '23': 543,\n",
       " '12': 687,\n",
       " '17': 1146,\n",
       " '15': 4477,\n",
       " '21': 1745,\n",
       " '20': 1722,\n",
       " '02': 1381,\n",
       " '18': 1439,\n",
       " '03': 421,\n",
       " '05': 464,\n",
       " '19': 1188,\n",
       " '01': 683,\n",
       " '22': 479,\n",
       " '08': 492,\n",
       " '04': 337,\n",
       " '00': 447,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '11': 641}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import the datetime module\n",
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    created_at = post[6]\n",
    "    num_comments = int(post[4])\n",
    "    result_list.append([created_at, num_comments])\n",
    "    \n",
    "#Create two empty dictionaries\n",
    "#loop through the result_list\n",
    "#parse the date and create datetime object\n",
    "#select the hour using strftime method\n",
    "#create dictionaries for the counts_by_hour and comments_by_hour\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    dt_str = row[0] #exxtract hour from the date\n",
    "    num_comments = row[1]\n",
    "    dt_obj = dt.datetime.strptime(dt_str, '%m/%d/%Y %H:%M')\n",
    "    hr_str = dt_obj.strftime('%H')\n",
    "    \n",
    "    if hr_str not in counts_by_hour:\n",
    "        counts_by_hour[hr_str] = 1\n",
    "        comments_by_hour[hr_str] = num_comments\n",
    "    else:\n",
    "        counts_by_hour[hr_str] += 1\n",
    "        comments_by_hour[hr_str] += num_comments\n",
    "        \n",
    "comments_by_hour\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Average Number of Comments by Hour\n",
    "We will use the **counts_by_hour** and **comments_by_hour** to calculate the average number of comments for _Ask HN_ posts by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hr in comments_by_hour:\n",
    "    avg_by_hour.append([hr, comments_by_hour[hr]/counts_by_hour[hr]])\n",
    "\n",
    "(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting and Printing Values from a List of Lists\n",
    "The format of the results we displayed above makes it difficult to identify the hours with the highest values. We will therefore sort the list of lists and print the five highest values in a formati that is easier to read and comprehend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.5777777777777775, '09'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [16.796296296296298, '16'],\n",
       " [7.985294117647059, '23'],\n",
       " [9.41095890410959, '12'],\n",
       " [11.46, '17'],\n",
       " [38.5948275862069, '15'],\n",
       " [16.009174311926607, '21'],\n",
       " [21.525, '20'],\n",
       " [23.810344827586206, '02'],\n",
       " [13.20183486238532, '18'],\n",
       " [7.796296296296297, '03'],\n",
       " [10.08695652173913, '05'],\n",
       " [10.8, '19'],\n",
       " [11.383333333333333, '01'],\n",
       " [6.746478873239437, '22'],\n",
       " [10.25, '08'],\n",
       " [7.170212765957447, '04'],\n",
       " [8.127272727272727, '00'],\n",
       " [9.022727272727273, '06'],\n",
       " [7.852941176470588, '07'],\n",
       " [11.051724137931034, '11']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an empty list;swap_avg_by_hour\n",
    "#swap the elements in the avg_by_hour list of lists\n",
    "#append the swapped elements to the empty list; swap_avg\n",
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort the swap_avg_by_hour in descending order\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "sorted_swap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "---------------------------------------\n",
      "15:00 : 38.59 average comments per post\n",
      "02:00 : 23.81 average comments per post\n",
      "20:00 : 21.52 average comments per post\n",
      "16:00 : 16.80 average comments per post\n",
      "21:00 : 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "#Print the Top 5 Hours for Ask Posts Comments\n",
    "\n",
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "print('---------------------------------------')\n",
    "for avg, hour in sorted_swap[:5]:    \n",
    "    hour_dt = dt.datetime.strptime(hour, '%H')\n",
    "    hour_str = hour_dt.strftime('%H:%M')\n",
    "    print('{} : {:.2f} average comments per post'.format(hour_str, avg))\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the findings, it appears that creating question posts at **3PM** in Hacker News is likely to receive more comments than any other time. Since I am located in Kenya, we adhere to EAT and therefore it will be appropriate to create a post at around **11PM** EAT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
